{
 "cells": [
  {
   "cell_type": "code",
   "id": "527196a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:46:03.886992Z",
     "start_time": "2025-07-11T00:46:02.199917Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from typing import List"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "338f2477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T00:46:04.139028Z",
     "start_time": "2025-07-11T00:46:03.941Z"
    }
   },
   "source": [
    "with open('annotations/thumos_14_anno.json', 'r') as f:\n",
    "    thumos_14_anno = json.load(f)\n",
    "    \n",
    "len(thumos_14_anno['database'].keys())"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'annotations/thumos_14_anno.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mannotations/thumos_14_anno.json\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mr\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m      2\u001B[39m     thumos_14_anno = json.load(f)\n\u001B[32m      4\u001B[39m \u001B[38;5;28mlen\u001B[39m(thumos_14_anno[\u001B[33m'\u001B[39m\u001B[33mdatabase\u001B[39m\u001B[33m'\u001B[39m].keys())\n",
      "\u001B[36mFile \u001B[39m\u001B[32mc:\\Users\\tamqu\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:326\u001B[39m, in \u001B[36m_modified_open\u001B[39m\u001B[34m(file, *args, **kwargs)\u001B[39m\n\u001B[32m    319\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m}:\n\u001B[32m    320\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    321\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mIPython won\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m by default \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    322\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    323\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33myou can use builtins\u001B[39m\u001B[33m'\u001B[39m\u001B[33m open.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    324\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m326\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'annotations/thumos_14_anno.json'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fffd285",
   "metadata": {},
   "outputs": [],
   "source": [
    "class THUMOSFeatureDataset(Dataset):\n",
    "    def __init__(self, feature_dir, anno_path, max_len=100):\n",
    "        self.feature_dir = feature_dir\n",
    "        self.max_len = max_len\n",
    "        with open(anno_path, \"r\") as f:\n",
    "            self.annotations = json.load(\n",
    "                f\n",
    "            ).database  # {\"video_name\": [{\"start\": float, \"end\": float, \"label\": int}, ...]}\n",
    "        self.video_list = list(self.annotations.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_name = self.video_list[idx]\n",
    "        feature_path = os.path.join(self.feature_dir, video_name + \".npy\")\n",
    "        feature = np.load(feature_path)\n",
    "\n",
    "        # Pad/Trim\n",
    "        if feature.shape[0] < self.max_len:\n",
    "            pad = np.zeros((self.max_len - feature.shape[0], feature.shape[1]))\n",
    "            feature = np.vstack([feature, pad])\n",
    "        else:\n",
    "            feature = feature[: self.max_len]\n",
    "\n",
    "        # Generate target maps\n",
    "        gt = self.annotations[video_name]  # list of actions\n",
    "        start_label = np.zeros(self.max_len)\n",
    "        end_label = np.zeros(self.max_len)\n",
    "        for a in gt:\n",
    "            start = int(a[\"segment\"][0] / 100 * self.max_len)\n",
    "            end = int(a[\"end\"][1] / 100 * self.max_len)\n",
    "            if 0 <= start < self.max_len:\n",
    "                start_label[start] = 1\n",
    "            if 0 <= end < self.max_len:\n",
    "                end_label[end] = 1\n",
    "\n",
    "        return (\n",
    "            torch.tensor(feature, dtype=torch.float32),\n",
    "            torch.tensor(start_label, dtype=torch.float32),\n",
    "            torch.tensor(end_label, dtype=torch.float32),\n",
    "            video_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full BMN-like Temporal Action Detection Model for THUMOS14\n",
    "# Includes: Dataset loading, model, training, proposal generation, and inference.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class THUMOSFeatureDataset(Dataset):\n",
    "    def __init__(self, feature_dir, anno_path, max_len=100):\n",
    "        self.feature_dir = feature_dir\n",
    "        self.max_len = max_len\n",
    "        with open(anno_path, 'r') as f:\n",
    "            self.annotations = json.load(f)  # {\"video_name\": [{\"start\": float, \"end\": float, \"label\": int}, ...]}\n",
    "        self.video_list = list(self.annotations.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_name = self.video_list[idx]\n",
    "        feature_path = os.path.join(self.feature_dir, video_name + \".npy\")\n",
    "        feature = np.load(feature_path)\n",
    "\n",
    "        # Pad/Trim\n",
    "        if feature.shape[0] < self.max_len:\n",
    "            pad = np.zeros((self.max_len - feature.shape[0], feature.shape[1]))\n",
    "            feature = np.vstack([feature, pad])\n",
    "        else:\n",
    "            feature = feature[:self.max_len]\n",
    "\n",
    "        # Generate target maps\n",
    "        gt = self.annotations[video_name]  # list of actions\n",
    "        start_label = np.zeros(self.max_len)\n",
    "        end_label = np.zeros(self.max_len)\n",
    "        for a in gt:\n",
    "            start = int(a['start'] / 100 * self.max_len)\n",
    "            end = int(a['end'] / 100 * self.max_len)\n",
    "            if 0 <= start < self.max_len:\n",
    "                start_label[start] = 1\n",
    "            if 0 <= end < self.max_len:\n",
    "                end_label[end] = 1\n",
    "\n",
    "        return (\n",
    "            torch.tensor(feature, dtype=torch.float32),\n",
    "            torch.tensor(start_label, dtype=torch.float32),\n",
    "            torch.tensor(end_label, dtype=torch.float32),\n",
    "            video_name\n",
    "        )\n",
    "\n",
    "# -------------------- BMN Minimal Model --------------------\n",
    "class BMNMinimal(nn.Module):\n",
    "    def __init__(self, input_dim=400, hidden_dim=256):\n",
    "        super(BMNMinimal, self).__init__()\n",
    "        self.base_conv = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.start_layer = nn.Conv1d(hidden_dim, 1, kernel_size=1)\n",
    "        self.end_layer = nn.Conv1d(hidden_dim, 1, kernel_size=1)\n",
    "        self.conf_layer = nn.Conv1d(hidden_dim, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, D) => (B, D, T)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        feat = self.base_conv(x)\n",
    "        start = torch.sigmoid(self.start_layer(feat)).squeeze(1)\n",
    "        end = torch.sigmoid(self.end_layer(feat)).squeeze(1)\n",
    "        conf = torch.sigmoid(self.conf_layer(feat)).squeeze(1)\n",
    "        return start, end, conf\n",
    "\n",
    "# -------------------- Loss Function --------------------\n",
    "def bmn_loss(start_pred, end_pred, conf_pred, start_gt, end_gt):\n",
    "    start_loss = F.binary_cross_entropy(start_pred, start_gt)\n",
    "    end_loss = F.binary_cross_entropy(end_pred, end_gt)\n",
    "    conf_loss = F.mse_loss(conf_pred, torch.max(start_gt, end_gt))\n",
    "    return start_loss + end_loss + conf_loss\n",
    "\n",
    "# -------------------- Proposal Generation --------------------\n",
    "def generate_proposals(start_scores, end_scores, conf_scores, threshold=0.5):\n",
    "    proposals = []\n",
    "    T = len(start_scores)\n",
    "    for i in range(T):\n",
    "        if start_scores[i] > threshold:\n",
    "            for j in range(i + 1, T):\n",
    "                if end_scores[j] > threshold:\n",
    "                    score = (start_scores[i] * end_scores[j] * conf_scores[i])\n",
    "                    proposals.append((i, j, score.item()))\n",
    "    proposals = sorted(proposals, key=lambda x: x[2], reverse=True)\n",
    "    return proposals[:100]  # top 100\n",
    "\n",
    "# -------------------- Inference --------------------\n",
    "def run_inference(model, dataloader, device):\n",
    "    model.eval()\n",
    "    results = {}\n",
    "    with torch.no_grad():\n",
    "        for features, _, _, vid in dataloader:\n",
    "            features = features.to(device)\n",
    "            start, end, conf = model(features)\n",
    "            props = generate_proposals(start[0], end[0], conf[0])\n",
    "            results[vid[0]] = props\n",
    "    return results\n",
    "\n",
    "# -------------------- Main Script --------------------\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    feature_dir = './data/thumos_features/'\n",
    "    anno_path = './data/thumos_val_annotations.json'\n",
    "\n",
    "    dataset = THUMOSFeatureDataset(feature_dir, anno_path)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    model = BMNMinimal()\n",
    "    model.to(device)\n",
    "\n",
    "    # Optional: load checkpoint\n",
    "    # model.load_state_dict(torch.load(\"bmn_model.pth\"))\n",
    "\n",
    "    results = run_inference(model, loader, device)\n",
    "    for vid, props in results.items():\n",
    "        print(f\"Video {vid}:\")\n",
    "        for s, e, score in props[:5]:\n",
    "            print(f\"  Start {s}, End {e}, Score {score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
